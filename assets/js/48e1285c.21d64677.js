"use strict";(self.webpackChunkwiki_loliot_net=self.webpackChunkwiki_loliot_net||[]).push([[59179],{94725:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>i,default:()=>m,frontMatter:()=>l,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"mlops/mlops/kubeflow/kserve/custom","title":"Kserve Custom Runtime","description":"Kserve Custom Runtime","source":"@site/docs/mlops/mlops/kubeflow/kserve/custom.mdx","sourceDirName":"mlops/mlops/kubeflow/kserve","slug":"/mlops/mlops/kubeflow/kserve/custom","permalink":"/docs/mlops/mlops/kubeflow/kserve/custom","draft":false,"unlisted":false,"editUrl":"https://github.com/hhk7734/wiki/tree/main/docs/mlops/mlops/kubeflow/kserve/custom.mdx","tags":[],"version":"current","lastUpdatedAt":1734103299000,"frontMatter":{"id":"custom","title":"Kserve Custom Runtime","sidebar_label":"Custom Runtime","description":"Kserve Custom Runtime","keywords":["kserve","Custom","ServingRuntimes","Transformer"]},"sidebar":"mlops","previous":{"title":"CRDs","permalink":"/docs/mlops/mlops/kubeflow/kserve/crds"},"next":{"title":"MLFlow","permalink":"/docs/mlops/mlops/kubeflow/kserve/mlflow"}}');var o=r(74848),t=r(28453);const l={id:"custom",title:"Kserve Custom Runtime",sidebar_label:"Custom Runtime",description:"Kserve Custom Runtime",keywords:["kserve","Custom","ServingRuntimes","Transformer"]},i=void 0,d={},a=[{value:"ServingRuntimes",id:"servingruntimes",level:2},{value:"Kserve Args",id:"kserve-args",level:3},{value:"Transformer",id:"transformer",level:2}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h2,{id:"servingruntimes",children:"ServingRuntimes"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"python3 -m pip install kserve\n"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"Storage"}),"\ub97c \uc0ac\uc6a9\ud574\uc57c\ud558\ub294 \uacbd\uc6b0 ",(0,o.jsx)(n.code,{children:"kserve[storage]"}),"\ub97c \uc124\uce58\ud574\uc57c\ud569\ub2c8\ub2e4."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"<project>\n\u251c\u2500\u2500 app/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 runtime/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 __main__.py\n\u2502   \u2502   \u2514\u2500\u2500 predictor.py\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 ...\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",metastring:'title="app/runtime/__main__.py"',children:'import argparse\n\nfrom kserve import ModelServer, model_server\n# from kserve.storage import Storage\n\nfrom app.runtime.predictor import DEFAULT_MODEL_NAME, Predictor\n\nparser = argparse.ArgumentParser(parents=[model_server.parser])\nparser.add_argument("--model_dir", required=True, help="A URI pointer to the model binary")\nparser.add_argument(\n    "--model_name", help="The name that the model is served under.", default=DEFAULT_MODEL_NAME\n)\nargs, _ = parser.parse_known_args()\n\nModelServer().start([Predictor(args.model_name, args.model_dir)])\n# ModelServer().start([Predictor(args.model_name, Storage.download(args.model_dir))])\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",metastring:'title="app/runtime/predictor.py"',children:'from kserve import InferRequest, InferResponse, Model\n\nDEFAULT_MODEL_NAME = "model"\nDEFAULT_LOCAL_MODEL_DIR = "/tmp/model"\n\n\nclass Predictor(Model):\n    def __init__(self, name: str = DEFAULT_MODEL_NAME, model_dir: str = DEFAULT_LOCAL_MODEL_DIR):\n        super().__init__(name)\n\n        self._model_dir = model_dir\n\n        self.load()\n\n    def load(self):\n        self.ready = True\n\n    async def preprocess(\n        self, payload: InferRequest, headers: dict[str, str] | None = None\n    ) -> InferRequest:\n        return payload\n\n    async def predict(\n        self, payload: InferRequest, headers: dict[str, str] | None = None\n    ) -> InferResponse:\n        return InferResponse(\n            response_id=payload.id,\n            model_name=self.name,\n            infer_outputs={},\n        )\n\n    def postprocess(\n        self, response: InferResponse, headers: dict[str, str] | None = None\n    ) -> InferResponse:\n        return response\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"python3 -m app.runtime\n"})}),"\n",(0,o.jsx)(n.h3,{id:"kserve-args",children:"Kserve Args"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://github.com/kserve/kserve/blob/master/python/kserve/kserve/model_server.py",children:"https://github.com/kserve/kserve/blob/master/python/kserve/kserve/model_server.py"})}),"\n"]}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["built-in flags","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"--http_port=8080"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"--grpc_port=8081"})}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"--workers=1"}),": RestAPI \ud504\ub85c\uc138\uc2a4"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"--max_threads=4"}),": gRPC \uc2a4\ub808\ub4dc"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"--max_asyncio_workers=<thread>"}),": \uc774\ubca4\ud2b8 \ub8e8\ud504 \uc2a4\ub808\ub4dc, \uae30\ubcf8\uac12: ",(0,o.jsx)(n.code,{children:"min(32, CPU + 4)"})]}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"--enable_grpc=true"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"--enable_docs_url=false"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"--enable_latency_logging=true"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"--configure_logging=true"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"--log_config_file=<path>"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"--access_log_format=<format>"})}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\ucd94\uac00","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"--model_dir=<path>"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.code,{children:"--model_name=<name>"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"transformer",children:"Transformer"}),"\n",(0,o.jsxs)(n.p,{children:["Transformer\ub294 ServingRuntimes\uc5d0\uc11c ",(0,o.jsx)(n.code,{children:"predict"}),"\ub9cc \uc81c\uc678\ud558\uace0 \uad6c\ud604\ud558\uba74 \ub429\ub2c8\ub2e4."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from kserve import InferRequest, InferResponse, Model\n\nDEFAULT_MODEL_NAME = "model"\n\n\nclass Predictor(Model):\n    def __init__(self, name: str = DEFAULT_MODEL_NAME):\n        super().__init__(name)\n\n    async def preprocess(\n        self, payload: InferRequest, headers: dict[str, str] | None = None\n    ) -> InferRequest:\n        return payload\n\n    def postprocess(\n        self, response: InferResponse, headers: dict[str, str] | None = None\n    ) -> InferResponse:\n        return response\n'})})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>i});var s=r(96540);const o={},t=s.createContext(o);function l(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:l(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);