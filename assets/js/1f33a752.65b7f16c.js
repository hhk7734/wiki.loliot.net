"use strict";(self.webpackChunkwiki_loliot_net=self.webpackChunkwiki_loliot_net||[]).push([[9221],{17452:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>u,frontMatter:()=>l,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"mlops/nn/llm/metrics","title":"Metrics for LLM inference","description":"Metrics for LLM inference","source":"@site/docs/mlops/nn/llm/metrics.mdx","sourceDirName":"mlops/nn/llm","slug":"/mlops/nn/llm/metrics","permalink":"/docs/mlops/nn/llm/metrics","draft":false,"unlisted":false,"editUrl":"https://github.com/hhk7734/wiki/tree/main/docs/mlops/nn/llm/metrics.mdx","tags":[],"version":"current","lastUpdatedAt":1756832216000,"frontMatter":{"id":"metrics","title":"Metrics for LLM inference","sidebar_label":"Metrics for inference","description":"Metrics for LLM inference","keywords":["Neural Network","Large Language Model","Metrics"]},"sidebar":"nn","previous":{"title":"Pragmatic Disaggregation (2506)","permalink":"/docs/mlops/nn/llm/pragmatic-disaggregation"}}');var r=i(74848),s=i(28453);const l={id:"metrics",title:"Metrics for LLM inference",sidebar_label:"Metrics for inference",description:"Metrics for LLM inference",keywords:["Neural Network","Large Language Model","Metrics"]},c=void 0,o={},d=[{value:"Token",id:"token",level:2},{value:"Latency",id:"latency",level:2},{value:"Throughput",id:"throughput",level:2},{value:"KV cache",id:"kv-cache",level:2}];function a(e){const n={h2:"h2",li:"li",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"token",children:"Token"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Input Sequence Length (ISL)"}),"\n",(0,r.jsx)(n.li,{children:"Output Sequence Length (OSL)"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"latency",children:"Latency"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Time To First Token (TTFT)","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"First Token Latency (FTL)"}),"\n",(0,r.jsx)(n.li,{children:"e.g. P90 TTFT < 1 s"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Time Per Output Token (TPOT)","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Inter-Token Latency (ITL)"}),"\n",(0,r.jsx)(n.li,{children:"Token-to-Token Latency (TTL)"}),"\n",(0,r.jsx)(n.li,{children:"Time Between Tokens (TBT)"}),"\n",(0,r.jsx)(n.li,{children:"e.g. P90 TPOT < 200 ms"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"End-to-End Latency (E2EL)"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"throughput",children:"Throughput"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Requests Per Second (RPS)","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Query Per Second (QPS)"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Tokens Per Second (TPS)"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"kv-cache",children:"KV cache"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"GPU KV cache usage"}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(a,{...e})}):a(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>c});var t=i(96540);const r={},s=t.createContext(r);function l(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);